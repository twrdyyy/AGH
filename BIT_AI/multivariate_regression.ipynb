{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "Today we're going to talk some more about last-time's topic - **Linear Regression** in a more generalized way. \n",
    "\n",
    "You'll see that with just a few changes, we will be able to apply Linear Regression model to problems much more interesting than plotting straight lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import solutions\n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from typing import Tuple, Optional, List\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previously\n",
    "\n",
    "### $$y = w_0 + w_1 \\cdot x$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = solutions.X_1\n",
    "Y = solutions.Y_1\n",
    "\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we want to find the optimal $(w_0, w_1)$ - our **model**\n",
    "\n",
    "* our model will be able to make a **hypothesis**\n",
    "\n",
    "### $$ h_W(x) = w_0 + w_1 \\cdot x$$\n",
    "\n",
    "* a **loss function** lets as calculate how well our model **fits** the data. In this case, the loss function could look like this:\n",
    "\n",
    "### $$L_{prev} = \\frac{1}{N}\\sum_{i=0}^N(h_W(x^{(i)}) - y^{(i)})^2 $$\n",
    " \n",
    " Though it's good enough for our purposes, we'll divide loss function by 2 - it won't change anything about it illustrating the quality of the model, but will simplify latter computations (can you guess how?)\n",
    " \n",
    "### $$L = \\frac{1}{2N}\\sum_{i=0}^N(h_W(x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "* We can find $(w_0, w_1)$ by using **Gradient Descent** method. \n",
    "\n",
    "* If we calculate gradients of $L$ with respect to $(w_0, w_1)$, or $\\dfrac{\\partial L}{\\partial w_0}$ and $\\dfrac{\\partial L}{\\partial w_1}$, we will know how to shift the values of $(w_0, w_1)$, so that they will fit the data better.\n",
    "\n",
    "### $$\n",
    "\\dfrac{\\partial L}{\\partial w_0} = \\dfrac{\\sum_{i=0}^n w_0 + w_1 x^{(i)} - y^{(i)}}{n} \\\\\n",
    "\\dfrac{\\partial L}{\\partial w_1} =  \\dfrac{\\sum_{i=0}^n (w_0 + w_1 x^{(i)} - y^{(i)}) \\cdot x^{(i)}}{n}\n",
    "$$\n",
    "\n",
    "![The idea of Gradient Descent](../1_regression/img/gradient_descent_0.png)\n",
    "\n",
    "* We multiply the gradients by a **learning rate** $\\alpha$, so that the updates are small and don't overshoot their objective.\n",
    "\n",
    "### $$\n",
    "w_0 = w_0 - \\dfrac{\\partial L}{\\partial w_0} \\cdot \\alpha \\\\\n",
    "w_1 = w_1 - \\dfrac{\\partial L}{\\partial w_1} \\cdot \\alpha\n",
    "$$\n",
    "* We repeat that process for an arbitrary number of **epochs**\n",
    "\n",
    "![Learning rates](../1_regression/img/learning_rate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"solutions\", \n",
    "    \"../1_regression/solutions.py\"\n",
    ")\n",
    "solutions_1 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(solutions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w_0 = np.random.rand()\n",
    "init_w_1 = np.random.rand()\n",
    "learning_rate = 0.01\n",
    "num_iterations = 100\n",
    "\n",
    "trained_w_0, trained_w_1, loss_history = \\\n",
    "    solutions_1.train_model(init_w_0, init_w_1, X, Y, learning_rate, num_iterations)\n",
    "\n",
    "plt.plot(list(range(num_iterations)), loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = trained_w_0 + trained_w_1 * X \n",
    "plt.scatter(X, Y)\n",
    "plt.plot(X, Y_pred, 'r')\n",
    "plt.show()\n",
    "print('w_0:', trained_w_0)\n",
    "print('w_1:', trained_w_1)\n",
    "print('Loss:', solutions_1.my_loss_vectorized(trained_w_0, trained_w_1, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's go bigger!\n",
    "\n",
    "Today, we'll apply linear regression to real-life data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset.data)\n",
    "df.columns = dataset.feature_names\n",
    "df['target'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're dealing with a dataset describing houses - each of them has **13** features. Let's see how each of them is related to our target - the price of the house!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns:\n",
    "    if feature != 'target':\n",
    "        print(f\"-------{feature}--------\")\n",
    "        plt.scatter(df[feature], df['target'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the plots, in most of them some kind of relationship can be observed.\n",
    "\n",
    "Now, is it possible to use what we already know to train a model which will make accurate enough predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference is that previously:\n",
    "\n",
    "### $$\\hat{y} = h_W(x) = w_0 + w_1x$$ \n",
    "\n",
    "And today:\n",
    "\n",
    "### $$\\hat{y} = h_W(x_1, x_2, ..., x_k) \\\\\n",
    "= w_0 + w_1x_1+ w_2x_2+ w_3x_3+ ... + w_kx_k \\\\\n",
    "= w_0 + \\sum_{i=1}^k w_i x_i$$ \n",
    "\n",
    "As you can see, $w_0$ has been left out from the sum, which makes it sad. Can we do something, which will make it possible to include it there?\n",
    "\n",
    "The simple solution is to add a *bias feature* to our input dataset - $X$ - i.e. add a column of ones to it.\n",
    "\n",
    "This way, for each datapoint $x^{(j)}$,  \n",
    "### $$x_0^{(j)} = 1$$\n",
    "and \n",
    "### $$ x_0^{(j)} \\cdot w_0 = w_0 $$\n",
    "\n",
    "therefore\n",
    "\n",
    "### $$ w_0 + \\sum_{i=1}^k w_i x_i^{(j)} =  \\sum_{i=0}^k w_i x_i^{(j)} = h_W(x^{(j)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating this manually every time is not a goood idea. \n",
    "\n",
    "Your task now is to implement a function which will compute the hypotheses for given data $(X)$ and model $(w_0, w_1, w_2, w_3, w_4, w_5, w_6, w_7, w_8, w_9, w_{10}, w_{11}, w_{12}, w_{13})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(\n",
    "    X: np.ndarray,\n",
    "    w_0: float, \n",
    "    w_1: float, \n",
    "    w_2: float, \n",
    "    w_3: float, \n",
    "    w_4: float, \n",
    "    w_5: float, \n",
    "    w_6: float, \n",
    "    w_7: float, \n",
    "    w_8: float, \n",
    "    w_9: float, \n",
    "    w_10: float, \n",
    "    w_11: float, \n",
    "    w_12: float, \n",
    "    w_13: float\n",
    ") -> np.ndarray:\n",
    "    pass\n",
    "    # PLEASE DON'T EVER DO THAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, I got tired of even writing this header!\n",
    "\n",
    "We obviously need something more elegant. This is why, from now on, we'll always think of particular datapoints not as numbers, but vectors of numbers. Therefore, the whole dataset will be a **vector of vectors** - a matrix.\n",
    "\n",
    "The same way, we won't care much for every particular weight in our model, we'll treat them as a single vector of numbers.\n",
    "\n",
    "So: \n",
    "### $$\n",
    "\\hat{y}^{(j)} = h_W(x^{(j)}) \\sum_{i=0}^k w_i x_i^{(j)} = \\sum Wx^{(j)} \n",
    "$$\n",
    "\n",
    "* $W$ has shape $[n_{features}]$\n",
    "* $X$ has shape $[n_{datapoints}, n_{features}]$\n",
    "* $Y$ has shape $[n_{datapoints}]$\n",
    "\n",
    "Please implement it. If you use numpy magic instead of iterating over columns, it should take you just one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypotheses(W: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    return np.zeros(X.size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = solutions.hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a sanity check on a few examples!\n",
    "W = np.random.rand(X.shape[1])\n",
    "print('your solution:', hypotheses(W, X[:5]))\n",
    "print('provided solution:', solutions.hypotheses(W, X[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also means we have to update the formula for the cost function:\n",
    "\n",
    "### $$\n",
    "L(w_0, w_1, ... w_n) = L(W) \\\\ \n",
    "= \\frac{1}{2N}\\sum_{i=0}^N(\\sum_{j=0}^k w_j x^{(i)}_j - y^{(i)})^2 \\\\\n",
    "= \\frac{1}{2N}\\sum_{i=0}^N (h_W(x^{(i)}) - y^{(i)})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(W: np.ndarray, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = solutions.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(X.shape[1])\n",
    "print('your solution:', loss(W, X, Y))\n",
    "print('provided solution:', solutions.loss(W, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and Gradient Steps\n",
    "\n",
    "For every iteration:\n",
    "* calculate partial derivatives of cost function with respect to every element of W:\n",
    "\n",
    "### $$\\epsilon_j = \\frac{\\partial}{\\partial w_j}L(W) = \\frac{1}{N} \\sum_{i=1}^N(h_W(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "* **simultaneously** update every element of W:\n",
    "\n",
    "### $$w_j = w_j - \\alpha \\epsilon_j$$ \n",
    "\n",
    "Where $\\alpha$ is our learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(\n",
    "    W: np.ndarray, \n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    learning_rate=0.01\n",
    ") -> np.ndarray:\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step = solutions.gradient_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(X.shape[1])\n",
    "print('your solution:', gradient_step(W, X, Y))\n",
    "print('provided solution:', solutions.gradient_step(W, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With all those tools at our disposal, let's train a model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    init_W: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    learning_rate: float,\n",
    "    num_iterations: int\n",
    ") -> Tuple[np.ndarray, List[float]]:\n",
    "    return init_W, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = solutions.train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_W = np.random.rand(X.shape[1])\n",
    "print('your solution:', train_model(init_W, X, Y, 0.1, 1))\n",
    "print('provided solution:', solutions.train_model(init_W, X, Y, 0.1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_W = np.random.rand(X.shape[1])\n",
    "num_iterations = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "trained_W, loss_hist = train_model(init_W, X, Y, learning_rate, num_iterations)\n",
    "\n",
    "plt.plot(np.arange(num_iterations), loss_hist)\n",
    "plt.show()\n",
    "\n",
    "Y_pred = hypotheses(trained_W, X)\n",
    "\n",
    "print('example targets', Y[:5])\n",
    "print('example predictions', Y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTF just happened?\n",
    "\n",
    "Our algorithms seem to be perfect, yet loss has exploded and our trained weights are NaNs! Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_format(to_print, name=None):\n",
    "    if name is not None: print(name)\n",
    "    print([\"%.2f\" % x for x in to_print])\n",
    "\n",
    "pretty_format(X.mean(axis=0), \"means\")\n",
    "pretty_format(X.max(axis=0) - X.min(axis=0), \"ranges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datapoints have very weird orders of magnitude, ranging form $10^0$ to $10^2$. \n",
    "\n",
    "Even though the initial weights are very small, you can guess what such initial values will do to the initial hypotheses, values of loss function and it's gradients. \n",
    "\n",
    "Moreover, due to the imbalance in the scales of features, the process of training itself will be slower, as updates in some weights will outweight updates in the others. \n",
    "\n",
    "![Normalization](img/normalization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling to the rescue!\n",
    "\n",
    "We want all our features to be roughly in the same range, i.e [-1, 1]. This is called **data normalization**. \n",
    "\n",
    "One way to achieve it is **mean normalization**:\n",
    "\n",
    "$$x_i = \\frac{x_i - \\mu_i}{max(x_i) - min(x_i)}$$\n",
    "\n",
    "The exception is the bias feature - $x_0$  - since it's always equal to 1 (just like we want i t to be), we don't normalize it!\n",
    "\n",
    "Now, implement a function which will calculate the mean-normalized Xs (and keep $X_0$ intact).\n",
    "The function should return normalized X and calculated means and ranges.\n",
    "We also want to be able to provide the function with pre-calculated means and ranges and use those, instead of calculating them from provided X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalization(\n",
    "    X: np.ndarray, \n",
    "    means: Optional[np.ndarray] = None, \n",
    "    ranges: Optional[np.ndarray] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    return X, means, ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_normalization = solutions.mean_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, X_mean, X_range = mean_normalization(X)\n",
    "X_norm_sol, X_mean_sol, X_range_sol = solutions.mean_normalization(X)\n",
    "\n",
    "pretty_format(X_mean, \"means yours\")\n",
    "pretty_format(X_mean_sol, \"means provided\")\n",
    "print()\n",
    "pretty_format(X_range, \"ranges yours\")\n",
    "pretty_format(X_range_sol, \"ranges provided\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do feature matrices have the same shapes?\n",
    "X.shape, X_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that our data has been normalized, let's try to train a model once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_W = np.random.rand(X_norm.shape[1])\n",
    "num_iterations = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "trained_W, loss_hist = train_model(init_W, X_norm, Y, learning_rate, num_iterations)\n",
    "\n",
    "plt.plot(np.arange(num_iterations), loss_hist)\n",
    "plt.show()\n",
    "\n",
    "Y_pred = hypotheses(trained_W, X_norm)\n",
    "\n",
    "print('example targets', Y[:5])\n",
    "print('example predictions', Y_pred[:5])\n",
    "print('final loss', loss_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it compare to a scikit-learn model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_norm, Y)\n",
    "Y_pred_regr = regressor.predict(X_norm)\n",
    "final_regressor_loss = np.mean((Y_pred_regr - Y) ** 2) / 2\n",
    "\n",
    "pretty_format(Y[:5], 'example targets')\n",
    "pretty_format(Y_pred[:5], 'example_predictions')\n",
    "pretty_format([loss_hist[-1]], 'final loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "As the final excercise, let's try to make things difficult for our model a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, things have been quite easy for our model - it was evaluated on the same data it hd been trained on. \n",
    "\n",
    "However, this is not the case in real life. What we care about is whether a trained model is able to make accurate predictions on the data it has never seen before.\n",
    "\n",
    "That's why, when training **any** model on **any** dataset, the first thing you must do is split the dataset into **training**, **validation** and **test** sets.\n",
    "\n",
    "For the simple models, validation set can be omitted, and today we'll see the usage of train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray,\n",
    "    ratio: float = 0.7\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    n_datapoints = X.shape[0]\n",
    "    assert(n_datapoints == Y.shape[0])\n",
    "    shuffled_indices = np.arange(n_datapoints)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    train_count = int(n_datapoints * ratio)\n",
    "    train_indices = shuffled_indices[:train_count]\n",
    "    test_indices = shuffled_indices[train_count:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember about data normalization!\n",
    "\n",
    "#### How to normalize previously unseen data?\n",
    "\n",
    "We have to make an assumption that the distribution of training data is close to the general distribution of data in our domain. In order for our normalization mapping to be coherent, we will normalize any test data using the means and ranges calculated from $X_{train}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_mean, X_range = mean_normalization(X_train)\n",
    "# this is why we keep normalization data\n",
    "X_test, X_mean, X_range = mean_normalization(X_test, X_mean, X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(\n",
    "    init_W: np.ndarray,\n",
    "    X_train: np.ndarray,\n",
    "    Y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    Y_test: np.ndarray,\n",
    "    learning_rate: float,\n",
    "    num_iterations: int\n",
    ") -> Tuple[np.ndarray, List[float], List[float]]:\n",
    "    \n",
    "    W = init_W\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "    for i in range(num_iterations):\n",
    "        train_loss_history.append(loss(W, X_train, Y_train))\n",
    "        test_loss_history.append(loss(W, X_test, Y_test))\n",
    "        W = gradient_step(W, X_train, Y_train, learning_rate)\n",
    "    return W, train_loss_history, test_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_W = np.random.rand(X_norm.shape[1])\n",
    "num_iterations = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "trained_W, train_loss_hist, test_loss_hist = train_test_model(\n",
    "    init_W, \n",
    "    X_train, \n",
    "    Y_train, \n",
    "    X_test, \n",
    "    Y_test, \n",
    "    learning_rate, \n",
    "    num_iterations\n",
    ")\n",
    "\n",
    "plt.plot(np.arange(num_iterations), train_loss_hist)\n",
    "plt.plot(np.arange(num_iterations), test_loss_hist, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = hypotheses(trained_W, X_test)\n",
    "pretty_format(Y[:5], 'example targets')\n",
    "pretty_format(Y_pred[:5], 'example_predictions')\n",
    "pretty_format([train_loss_hist[-1], test_loss_hist[-1]], 'final loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictions are not quite perfect and loss leaves something to be desired. \n",
    "But we also see, that our model has learnt *some* intuition about making predictions from real-life data, including data it has never seen before. \n",
    "\n",
    "That's pretty good!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bit_ai]",
   "language": "python",
   "name": "conda-env-bit_ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
